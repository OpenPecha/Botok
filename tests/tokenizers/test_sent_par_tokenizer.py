import pytest

from pathlib import Path

from botok import paragraph_tokenizer, sentence_tokenizer


text = (
    "བཀུར་བར་མི་འགྱུར་ཞིང༌། །བརྙས་བཅོས་མི་སྙན་རྗོད་པར་བྱེད། །དབང་དང་འབྱོར་པ་ལྡན་པ་ཡི། །རྒྱལ་རིགས་ཕལ་ཆེར་བག་མེད་པས། །"
    "མྱོས་པའི་གླང་ཆེན་བཞིན་དུ་འཁྱམས། །དེ་ཡི་འཁོར་ཀྱང་དེ་འདྲར་འགྱུར། །གཞན་ཡང་རྒྱལ་པོ་རྒྱལ་རིགས་ཀྱི། །སྤྱོད་པ་བཟང་ངན་ཅི་འདྲ་བ། །"
    "དེ་འདྲའི་ཚུལ་ལ་བལྟས་ནས་སུ། །འབངས་རྣམས་དེ་དང་དེ་འདྲ་སྟེ། །རྒྱལ་པོ་ནོར་ལ་བརྐམས་གྱུར་ན། །ནོར་གྱིས་རྒྱལ་ཁྲིམས་བསླུ་བར་རྩོམ། །"
    "མི་བདག་གཡེམ་ལ་དགའ་གྱུར་ན། །འཕྱོན་མའི་ཚོགས་རྣམས་མགོ་འཕང་མཐོ། །ཕྲ་མར་ཉན་ན་དབྱེན་གྱིས་གཏོར། །བརྟག་དཔྱད་མི་ཤེས་རྫུན་གྱིས་སླུ། །"
    "ང་ལོ་ཡང་ན་ཀུན་གྱིས་བསྐྱོད། །ངོ་དགར་བརྩི་ན་ཟོལ་ཚིག་སྨྲ། །དེ་དང་དེ་ལ་སོགས་པ་ཡི། །མི་བདག་དེ་ལ་གང་གང་གིས། །"
    "བསླུ་བར་རུང་བའི་སྐབས་མཐོང་ན། །གཡོན་ཅན་ཚོགས་ཀྱིས་ཐབས་དེ་སེམས། །མི་རྣམས་རང་འདོད་སྣ་ཚོགས་ལ། །རྒྱལ་པོ་ཀུན་གྱི་ཐུན་མོང་ཕྱིར། །"
    "རྒྱལ་པོས་བསམ་གཞིགས་མ་བྱས་ན། །ཐ་མར་རྒྱལ་སྲིད་འཇིག་པར་འགྱུར། །ཆེན་པོའི་གོ་སར་གནས་པ་ལ། །སྐྱོན་ཀྱང་ཡོན་ཏན་ཡིན་ཚུལ་དུ། །"
    "འཁོར་ངན་རྣམས་ཀྱིས་ངོ་བསྟོད་སྨྲ། །དེ་ཕྱིར་སྐྱོན་ཡོན་ཤེས་པ་དཀའ། །ལྷག་པར་རྩོད་ལྡན་སྙིགས་མའི་ཚེ། །འཁོར་གྱི་ནང་ན་མ་རབས་མང༌། །"
    "སྐྱོན་ཡང་ཡོན་ཏན་ལྟར་མཐོང་ལ། །རང་འདོད་ཆེ་ཞིང་རྒྱལ་པོ་བསླུ། །ཆུས་དང་འཁོར་གྱི་བདེ་ཐབས་ལ། །བསམ་གཞིགས་བྱེད་པ་དཀོན་པའི་ཕྱིར། །"
    "རྒྱལ་པོས་ལེགས་པར་དཔྱད་ནས་སུ། །བདེན་པའི་ངག་ལས་"
)


@pytest.fixture
def tokens(wt):
    return wt.tokenize(text, split_affixes=True)


@pytest.mark.skip(reason="not a config bug")
def test_sent_tokenizer(tokens):
    sents = sentence_tokenizer(tokens)

    out = ["".join([word.text for word in s['tokens']]) for s in sents]
    expected = [
        "བཀུར་བར་མི་འགྱུར་ཞིང༌། །བརྙས་བཅོས་མི་སྙན་རྗོད་པར་བྱེད། །",
        "དབང་དང་འབྱོར་པ་ལྡན་པ་ཡི། །རྒྱལ་རིགས་ཕལ་ཆེར་བག་མེད་པས། །མྱོས་པའི་གླང་ཆེན་བཞིན་དུ་འཁྱམས། །དེ་ཡི་འཁོར་ཀྱང་དེ་འདྲར་འགྱུར། །",
        "གཞན་ཡང་རྒྱལ་པོ་རྒྱལ་རིགས་ཀྱི། །སྤྱོད་པ་བཟང་ངན་ཅི་འདྲ་བ། །དེ་འདྲའི་ཚུལ་ལ་བལྟས་ནས་སུ། །འབངས་རྣམས་དེ་དང་དེ་འདྲ་སྟེ། །",
        "རྒྱལ་པོ་ནོར་ལ་བརྐམས་གྱུར་ན། །",
        "ནོར་གྱིས་རྒྱལ་ཁྲིམས་བསླུ་བར་རྩོམ། །",
        "མི་བདག་གཡེམ་ལ་དགའ་གྱུར་ན། །",
        "འཕྱོན་མའི་ཚོགས་རྣམས་མགོ་འཕང་མཐོ། །",
        "ཕྲ་མར་ཉན་ན་དབྱེན་གྱིས་གཏོར། །",
        "བརྟག་དཔྱད་མི་ཤེས་རྫུན་གྱིས་སླུ། །ང་ལོ་ཡང་ན་ཀུན་གྱིས་བསྐྱོད། །",
        "ངོ་དགར་བརྩི་ན་ཟོལ་ཚིག་སྨྲ། །",
        "དེ་དང་དེ་ལ་སོགས་པ་ཡི། །མི་བདག་དེ་ལ་གང་གང་གིས། །བསླུ་བར་རུང་བའི་སྐབས་མཐོང་ན། །",
        "གཡོན་ཅན་ཚོགས་ཀྱིས་ཐབས་དེ་སེམས། །མི་རྣམས་རང་འདོད་སྣ་ཚོགས་ལ། །རྒྱལ་པོ་ཀུན་གྱི་ཐུན་མོང་ཕྱིར། །རྒྱལ་པོས་བསམ་གཞིགས་མ་བྱས་ན། །",
        "ཐ་མར་རྒྱལ་སྲིད་འཇིག་པར་འགྱུར། །",
        "ཆེན་པོའི་གོ་སར་གནས་པ་ལ། །སྐྱོན་ཀྱང་ཡོན་ཏན་ཡིན་ཚུལ་དུ། །འཁོར་ངན་རྣམས་ཀྱིས་ངོ་བསྟོད་སྨྲ། །",
        "དེ་ཕྱིར་སྐྱོན་ཡོན་ཤེས་པ་དཀའ། །",
        "ལྷག་པར་རྩོད་ལྡན་སྙིགས་མའི་ཚེ། །འཁོར་གྱི་ནང་ན་མ་རབས་མང༌། །",
        "སྐྱོན་ཡང་ཡོན་ཏན་ལྟར་མཐོང་ལ། །རང་འདོད་ཆེ་ཞིང་རྒྱལ་པོ་བསླུ། །ཆུས་དང་འཁོར་གྱི་བདེ་ཐབས་ལ། །བསམ་གཞིགས་བྱེད་པ་དཀོན་པའི་ཕྱིར། །རྒྱལ་པོས་ལེགས་པར་དཔྱད་ནས་",
        "སུ། །བདེན་པའི་ངག་ལས་",
    ]
    assert out == expected

def test_normalized_sentence(tokens):
    sents = sentence_tokenizer(tokens)

    norm_sentences = [sentence['norm_sent'] for sentence in sents]
    expected = [
        "བཀུར་བ་ -ར་ མི་ འགྱུར་ ཞིང་ ། །",
        "བརྙས་བཅོས་ མི་ སྙན་ རྗོད་པ་ -ར་ བྱེད་ ། །",
        "དབང་ དང་ འབྱོར་པ་ ལྡན་པ་ ཡི་ ། ། རྒྱལ་རིགས་ ཕལ་ཆེར་ བག་མེད་པ་ -ས་ ། ། མྱོས་པ་ -འི་ གླང་ཆེན་ བཞིན་ དུ་ འཁྱམས་ ། ། དེ་ ཡི་ འཁོར་ ཀྱང་ དེ་ འདྲ་ -ར་ འགྱུར་ ། །",
        "གཞན་ ཡང་ རྒྱལ་པོ་ རྒྱལ་རིགས་ ཀྱི་ ། ། སྤྱོད་པ་ བཟང་ངན་ ཅི་འདྲ་བ་ ། ། དེ་ འདྲ་ -འི་ ཚུལ་ ལ་ བལྟས་ ནས་ སུ་ ། ། འབངས་ རྣམས་ དེ་ དང་ དེ་ འདྲ་ སྟེ་ ། །",
        "རྒྱལ་པོ་ ནོར་ ལ་ བརྐམས་ གྱུར་ ན་ ། །",
        "ནོར་ གྱིས་ རྒྱལ་ཁྲིམས་ བསླུ་བ་ -ར་ རྩོམ་ ། །",
        "མི་བདག་ གཡེམ་ ལ་ དགའ་ གྱུར་ ན་ ། །",
        "འཕྱོན་མ་ -འི་ ཚོགས་ རྣམས་ མགོ་འཕང་ མཐོ་ ། །",
        "ཕྲ་མ་ -ར་ ཉན་ ན་ དབྱེན་ གྱིས་ གཏོར་ ། །",
        "བརྟག་དཔྱད་ མི་ ཤེས་ རྫུན་ གྱིས་ སླུ་ ། ། ང་ ལོ་ ཡང་ན་ ཀུན་ གྱིས་ བསྐྱོད་ ། །",
        "ངོ་དགའ་ -ར་ བརྩི་ ན་ ཟོལ་ཚིག་ སྨྲ་ ། །",
        "དེ་ དང་ དེ་ ལ་སོགས་པ་ ཡི་ ། ། མི་བདག་ དེ་ ལ་ གང་ གང་ གིས་ ། ། བསླུ་བ་ -ར་ རུང་བ་ -འི་ སྐབས་ མཐོང་ ན་ ། །",
        "གཡོན་ཅན་ ཚོགས་ ཀྱིས་ ཐབས་ དེ་ སེམས་ ། ། མི་ རྣམས་ རང་འདོད་ སྣ་ཚོགས་ ལ་ ། །",
        "རྒྱལ་པོ་ ཀུན་ གྱི་ ཐུན་མོང་ ཕྱིར་ ། ། རྒྱལ་པོ་ -ས་ བསམ་ གཞིགས་ མ་ བྱས་ ན་ ། །",
        "ཐ་མ་ -ར་ རྒྱལ་སྲིད་ འཇིག་པ་ -ར་ འགྱུར་ ། །",
        "ཆེན་པོ་ -འི་ གོ་ས་ -ར་ གནས་པ་ ལ་ ། །",
        "སྐྱོན་ ཀྱང་ ཡོན་ཏན་ ཡིན་ཚུལ་ དུ་ ། ། འཁོར་ ངན་ རྣམས་ ཀྱིས་ ངོ་བསྟོད་ སྨྲ་ ། །",
        "དེ་ཕྱིར་ སྐྱོན་ཡོན་ ཤེས་པ་ དཀའ་ ། །",
        "ལྷག་པར་ རྩོད་ ལྡན་ སྙིགས་མ་ -འི་ ཚེ་ ། ། འཁོར་ གྱི་ ནང་ ན་མ་ རབས་ མང་ ། །",
        "སྐྱོན་ ཡང་ ཡོན་ཏན་ ལྟར་ མཐོང་ ལ་ ། །",
        "རང་འདོད་ ཆེ་ ཞིང་ རྒྱལ་པོ་ བསླུ་ ། ། ཆུས་ དང་ འཁོར་ གྱི་ བདེ་ ཐབས་ ལ་ ། །",
        "བསམ་ གཞིགས་ བྱེད་པ་ དཀོན་པ་ -འི་ ཕྱིར་ ། ། རྒྱལ་པོ་ -ས་ ལེགས་པ་ -ར་ དཔྱད་ ནས་ སུ་ ། ། བདེན་པ་ -འི་ ངག་ ལས་",
    ]
    assert norm_sentences == expected


def test_par_tokenizer(tokens):
    pars = paragraph_tokenizer(tokens)

    out = ["".join([word.text for word in p[1]]) for p in pars]
    expected = [
        "བཀུར་བར་མི་འགྱུར་ཞིང༌། །བརྙས་བཅོས་མི་སྙན་རྗོད་པར་བྱེད། །དབང་དང་འབྱོར་པ་ལྡན་པ་ཡི། །རྒྱལ་རིགས་ཕལ་ཆེར་བག་མེད་པས། །"
        "མྱོས་པའི་གླང་ཆེན་བཞིན་དུ་འཁྱམས། །དེ་ཡི་འཁོར་ཀྱང་དེ་འདྲར་འགྱུར། །གཞན་ཡང་རྒྱལ་པོ་རྒྱལ་རིགས་ཀྱི། །སྤྱོད་པ་བཟང་ངན་ཅི་འདྲ་བ། །"
        "དེ་འདྲའི་ཚུལ་ལ་བལྟས་ནས་སུ། །འབངས་རྣམས་དེ་དང་དེ་འདྲ་སྟེ། །རྒྱལ་པོ་ནོར་ལ་བརྐམས་གྱུར་ན། །ནོར་གྱིས་རྒྱལ་ཁྲིམས་བསླུ་བར་རྩོམ། །"
        "མི་བདག་གཡེམ་ལ་དགའ་གྱུར་ན། །འཕྱོན་མའི་ཚོགས་རྣམས་མགོ་འཕང་མཐོ། །ཕྲ་མར་ཉན་ན་དབྱེན་གྱིས་གཏོར། །བརྟག་དཔྱད་མི་ཤེས་རྫུན་གྱིས་སླུ། །"
        "ང་ལོ་ཡང་ན་ཀུན་གྱིས་བསྐྱོད། །ངོ་དགར་བརྩི་ན་ཟོལ་ཚིག་སྨྲ། །དེ་དང་དེ་ལ་སོགས་པ་ཡི། །མི་བདག་དེ་ལ་གང་གང་གིས། །བསླུ་བར་རུང་བའི་སྐབས་མཐོང་ན། །",
        "གཡོན་ཅན་ཚོགས་ཀྱིས་ཐབས་དེ་སེམས། །མི་རྣམས་རང་འདོད་སྣ་ཚོགས་ལ། །རྒྱལ་པོ་ཀུན་གྱི་ཐུན་མོང་ཕྱིར། །རྒྱལ་པོས་བསམ་གཞིགས་མ་བྱས་ན། །"
        "ཐ་མར་རྒྱལ་སྲིད་འཇིག་པར་འགྱུར། །ཆེན་པོའི་གོ་སར་གནས་པ་ལ། །སྐྱོན་ཀྱང་ཡོན་ཏན་ཡིན་ཚུལ་དུ། །འཁོར་ངན་རྣམས་ཀྱིས་ངོ་བསྟོད་སྨྲ། །"
        "དེ་ཕྱིར་སྐྱོན་ཡོན་ཤེས་པ་དཀའ། །ལྷག་པར་རྩོད་ལྡན་སྙིགས་མའི་ཚེ། །འཁོར་གྱི་ནང་ན་མ་རབས་མང༌། །སྐྱོན་ཡང་ཡོན་ཏན་ལྟར་མཐོང་ལ། །"
        "རང་འདོད་ཆེ་ཞིང་རྒྱལ་པོ་བསླུ། །ཆུས་དང་འཁོར་གྱི་བདེ་ཐབས་ལ། །བསམ་གཞིགས་བྱེད་པ་དཀོན་པའི་ཕྱིར། །རྒྱལ་པོས་ལེགས་པར་དཔྱད་ནས་སུ། །བདེན་པའི་ངག་ལས་",
    ]
    assert out == expected
